{"name":"Smart Web Scraper - Production v3 (Safe)","active":false,"nodes":[{"parameters":{"httpMethod":"POST","path":"scrape","authentication":"headerAuth","responseMode":"lastNode","options":{}},"name":"Webhook (Header Auth)","type":"n8n-nodes-base.webhook","position":[250,300],"webhookId":"scraper-webhook","credentials":{"httpHeaderAuth":{"id":"1","name":"Scraper API Key"}}},{"parameters":{"functionCode":"// ENHANCED INPUT VALIDATION + SSRF PROTECTION\nconst urls = Array.isArray($json.urls) ? $json.urls : [$json.url];\nconst selector = $json.selector || 'main, article, .content, body';\n\nfunction isIPBlocked(host) {\n  const blockedRegex = /^(127|10|192\\.168|172\\.(1[6-9]|2[0-9]|3[01])|0\\.|169\\.254|::1)/;\n  if (blockedRegex.test(host) || host === 'localhost') return true;\n  return false;\n}\n\nconst blockedHosts = [\"metadata.google.internal\", \"metadata.azure.com\"];\nconst validUrls = [];\nconst invalidUrls = [];\n\nfor (const url of urls) {\n  try {\n    if (!url || !url.startsWith('http')) {\n      invalidUrls.push({ url, reason: 'Invalid URL format' });\n      continue;\n    }\n    const urlObj = new URL(url);\n    if (isIPBlocked(urlObj.hostname) || blockedHosts.some(blocked=>urlObj.hostname.includes(blocked))) {\n      invalidUrls.push({ url, reason: 'SSRF/IP detected - blocked host' });\n      continue;\n    }\n    validUrls.push({\n      url,\n      selector,\n      requestId: `scrape-${Date.now()}-${validUrls.length}`,\n      timestamp: new Date().toISOString()\n    });\n  } catch (error) {\n    invalidUrls.push({ url, reason: error.message });\n  }\n}\n\nif (validUrls.length === 0) {\n  throw new Error('No valid URLs to scrape');\n}\n\nreturn validUrls.map(urlData => ({json: urlData}));"},"name":"Input Validator (Enhanced)","type":"n8n-nodes-base.code","position":[450,300]},{"parameters":{"batchSize":1,"options":{}},"name":"Loop Over URLs","type":"n8n-nodes-base.splitInBatches","position":[650,300]},{"parameters":{"url":"={{$json.url}}","options":{"timeout":30000},"headerParameters":{"parameters":[{"name":"User-Agent","value":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0"},{"name":"Accept","value":"text/html,application/xhtml+xml"}]}},"name":"HTTP Request","type":"n8n-nodes-base.httpRequest","position":[850,300]},{"parameters":{"functionCode":"// Extract and clean content\nconst html = $input.item.body;\nconst url = $input.item.json.url;\nconst requestId = $input.item.json.requestId;\n\ntry {\n  const titleMatch = /<title>(.*?)<\\/title>/i.exec(html);\n  const title = titleMatch ? titleMatch[1] : '';\n  \n  const mainRegex = /<main.*?>([\\s\\S]+?)<\\/main>/i;\n  const articleRegex = /<article.*?>([\\s\\S]+?)<\\/article>/i;\n  const bodyRegex = /<body.*?>([\\s\\S]+?)<\\/body>/i;\n  \n  let mainContent = mainRegex.exec(html)?.[1] || \n                    articleRegex.exec(html)?.[1] || \n                    bodyRegex.exec(html)?.[1] || \n                    html;\n  \n  mainContent = mainContent\n    .replace(/<script[^>]*>.*?<\\/script>/gis, '')\n    .replace(/<style[^>]*>.*?<\\/style>/gis, '')\n    .replace(/<[^>]+>/g, ' ')\n    .replace(/\\s+/g, ' ')\n    .trim()\n    .substring(0, 50000);\n  \n  const links = [];\n  const linkRegex = /<a[^>]*href=\\\"([^\\\"]+)\\\"[^>]*>(.*?)<\\/a>/gi;\n  let m;\n  let count = 0;\n  while ((m = linkRegex.exec(html)) !== null && count < 100) {\n    if (m[1] && !m[1].startsWith('#')) {\n      links.push({url: m[1], text: m[2].trim()});\n      count++;\n    }\n  }\n  \n  return {\n    json: {\n      success: true,\n      url,\n      requestId,\n      runner: 'http_basic',\n      timestamp: new Date().toISOString(),\n      data: {\n        title,\n        text_content: mainContent,\n        links,\n        meta: {\n          text_length: mainContent.length,\n          links_count: links.length\n        }\n      }\n    }\n  };\n} catch (error) {\n  return {\n    json: {\n      success: false,\n      url,\n      requestId,\n      error: `Extraction failed: ${error.message}`,\n      runner: 'http_basic',\n      timestamp: new Date().toISOString()\n    }\n  };\n}"},"name":"Extract & Clean Content","type":"n8n-nodes-base.code","position":[1050,300]}],"connections":{"Webhook (Header Auth)":{"main":[[{"node":"Input Validator (Enhanced)","type":"main","index":0}]]},"Input Validator (Enhanced)":{"main":[[{"node":"Loop Over URLs","type":"main","index":0}]]},"Loop Over URLs":{"main":[[{"node":"HTTP Request","type":"main","index":0}]]},"HTTP Request":{"main":[[{"node":"Extract & Clean Content","type":"main","index":0}]]},"Extract & Clean Content":{"main":[[{"node":"Loop Over URLs","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"}}