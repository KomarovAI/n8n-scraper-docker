name: CI/CD Tests

on:
  push:
    branches: [ main ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.ai-optimized'
      - 'AI_MANIFEST.md'
      - 'OPTIMIZATION_REPORT.md'
      - 'QUICKSTART.md'
      - 'ARCHITECTURE.md'
      - '.env.example'
  pull_request:
    branches: [ main ]
    paths-ignore:
      - '**.md'
      - 'docs/**'
  workflow_dispatch:

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Job 1: Skip duplicate runs
  skip-duplicate:
    name: Skip Duplicate Actions
    runs-on: ubuntu-latest
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
      - id: skip_check
        uses: fkirc/skip-duplicate-actions@v5
        with:
          concurrent_skipping: 'same_content_newer'
          skip_after_successful_duplicate: 'true'

  # Job 2: Validate docker-compose
  validate-compose:
    name: Validate docker-compose.yml
    runs-on: ubuntu-latest
    needs: skip-duplicate
    if: needs.skip-duplicate.outputs.should_skip != 'true'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate docker-compose syntax
        run: |
          docker compose config > /dev/null
          echo "âœ… docker-compose.yml is valid"

      - name: Check for .env.example
        run: |
          test -f .env.example || (echo "âŒ .env.example not found" && exit 1)
          echo "âœ… .env.example exists"

      - name: Capture job output logs
        if: always()
        run: |
          mkdir -p /tmp/job-logs
          echo "Job: ${{ github.job }}" > /tmp/job-logs/${{ github.job }}.log
          echo "Status: ${{ job.status }}" >> /tmp/job-logs/${{ github.job }}.log
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> /tmp/job-logs/${{ github.job }}.log
          echo "---" >> /tmp/job-logs/${{ github.job }}.log

      - name: Upload job logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.job }}-${{ github.run_number }}
          path: /tmp/job-logs/*.log
          retention-days: 7

  # Job 3: Lint Dockerfiles
  lint-dockerfiles:
    name: Lint Dockerfiles
    runs-on: ubuntu-latest
    needs: skip-duplicate
    if: needs.skip-duplicate.outputs.should_skip != 'true'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Lint with Hadolint
        uses: hadolint/hadolint-action@v3.1.0
        with:
          dockerfile: Dockerfile.n8n-enhanced
          ignore: DL3008,DL3009,DL3015
          failure-threshold: error

      - name: Capture job output logs
        if: always()
        run: |
          mkdir -p /tmp/job-logs
          echo "Job: ${{ github.job }}" > /tmp/job-logs/${{ github.job }}.log
          echo "Status: ${{ job.status }}" >> /tmp/job-logs/${{ github.job }}.log
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> /tmp/job-logs/${{ github.job }}.log
          echo "---" >> /tmp/job-logs/${{ github.job }}.log

      - name: Upload job logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.job }}-${{ github.run_number }}
          path: /tmp/job-logs/*.log
          retention-days: 7

  # Job 4: Check shell scripts
  check-shell-scripts:
    name: Check Shell Scripts
    runs-on: ubuntu-latest
    needs: skip-duplicate
    if: needs.skip-duplicate.outputs.should_skip != 'true'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install ShellCheck
        run: sudo apt-get update && sudo apt-get install -y shellcheck

      - name: Run ShellCheck
        run: |
          if ls scripts/*.sh 1> /dev/null 2>&1 || ls tests/**/*.sh 1> /dev/null 2>&1; then
            find . -type f -name "*.sh" -exec shellcheck {} \;
            echo "âœ… Shell scripts validated"
          else
            echo "â„¹ï¸ No shell scripts found"
          fi

      - name: Capture job output logs
        if: always()
        run: |
          mkdir -p /tmp/job-logs
          echo "Job: ${{ github.job }}" > /tmp/job-logs/${{ github.job }}.log
          echo "Status: ${{ job.status }}" >> /tmp/job-logs/${{ github.job }}.log
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> /tmp/job-logs/${{ github.job }}.log
          echo "---" >> /tmp/job-logs/${{ github.job }}.log

      - name: Upload job logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.job }}-${{ github.run_number }}
          path: /tmp/job-logs/*.log
          retention-days: 7

  # Job 5: Security - Trivy filesystem scan
  trivy-scan:
    name: Trivy Security Scan
    runs-on: ubuntu-latest
    needs: skip-duplicate
    if: needs.skip-duplicate.outputs.should_skip != 'true'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload Trivy results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Capture job output logs
        if: always()
        run: |
          mkdir -p /tmp/job-logs
          echo "Job: ${{ github.job }}" > /tmp/job-logs/${{ github.job }}.log
          echo "Status: ${{ job.status }}" >> /tmp/job-logs/${{ github.job }}.log
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> /tmp/job-logs/${{ github.job }}.log
          echo "---" >> /tmp/job-logs/${{ github.job }}.log

      - name: Upload job logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.job }}-${{ github.run_number }}
          path: /tmp/job-logs/*.log
          retention-days: 7

  # Job 6: Security - Secret detection
  secret-scan:
    name: Secret Detection
    runs-on: ubuntu-latest
    needs: skip-duplicate
    if: needs.skip-duplicate.outputs.should_skip != 'true'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: TruffleHog Secret Scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: HEAD

      - name: Capture job output logs
        if: always()
        run: |
          mkdir -p /tmp/job-logs
          echo "Job: ${{ github.job }}" > /tmp/job-logs/${{ github.job }}.log
          echo "Status: ${{ job.status }}" >> /tmp/job-logs/${{ github.job }}.log
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> /tmp/job-logs/${{ github.job }}.log
          echo "---" >> /tmp/job-logs/${{ github.job }}.log

      - name: Upload job logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.job }}-${{ github.run_number }}
          path: /tmp/job-logs/*.log
          retention-days: 7

  # Job 7: Build n8n-enhanced
  build-n8n:
    name: Build n8n-enhanced
    runs-on: ubuntu-latest
    needs: [validate-compose, lint-dockerfiles]
    if: needs.skip-duplicate.outputs.should_skip != 'true'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Build Docker image
        run: |
          docker build -f Dockerfile.n8n-enhanced -t n8n-enhanced:test .
          echo "âœ… n8n-enhanced image built successfully"

      - name: Capture job output logs
        if: always()
        run: |
          mkdir -p /tmp/job-logs
          echo "Job: ${{ github.job }}" > /tmp/job-logs/${{ github.job }}.log
          echo "Status: ${{ job.status }}" >> /tmp/job-logs/${{ github.job }}.log
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> /tmp/job-logs/${{ github.job }}.log
          echo "---" >> /tmp/job-logs/${{ github.job }}.log

      - name: Upload job logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs-${{ github.job }}-${{ github.run_number }}
          path: /tmp/job-logs/*.log
          retention-days: 7

  # Job 8: Test Summary with FULL AI-OPTIMIZED REPORTING
  test-summary:
    name: ðŸ“Š Unified AI Test Summary
    runs-on: ubuntu-latest
    needs: 
      - validate-compose
      - lint-dockerfiles
      - check-shell-scripts
      - trivy-scan
      - secret-scan
      - build-n8n
    if: always()
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Calculate Test Results
        id: results
        run: |
          TOTAL=6
          PASSED=0
          FAILED=0
          
          [[ "${{ needs.validate-compose.result }}" == "success" ]] && ((PASSED++)) || ((FAILED++))
          [[ "${{ needs.lint-dockerfiles.result }}" == "success" ]] && ((PASSED++)) || ((FAILED++))
          [[ "${{ needs.check-shell-scripts.result }}" == "success" ]] && ((PASSED++)) || ((FAILED++))
          [[ "${{ needs.trivy-scan.result }}" == "success" ]] && ((PASSED++)) || ((FAILED++))
          [[ "${{ needs.secret-scan.result }}" == "success" ]] && ((PASSED++)) || ((FAILED++))
          [[ "${{ needs.build-n8n.result }}" == "success" ]] && ((PASSED++)) || ((FAILED++))
          
          SUCCESS_RATE=$((PASSED * 100 / TOTAL))
          
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "success_rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Results: $PASSED/$TOTAL passed ($SUCCESS_RATE%)"
      
      - name: Create Unified Report Structure
        run: |
          mkdir -p unified-report/logs
          echo "ðŸ“ Created unified-report directory structure"
      
      - name: Generate Enhanced CTRF Report
        run: |
          START_TIME=$(date -d '10 minutes ago' +%s)000
          STOP_TIME=$(date +%s)000
          DURATION=$((STOP_TIME - START_TIME))
          
          cat > unified-report/ctrf-report.json << 'CTRF_EOF'
{
  "results": {
    "tool": {
      "name": "n8n-scraper-docker CI/CD",
      "version": "1.0.0"
    },
    "summary": {
      "tests": ${{ steps.results.outputs.total }},
      "passed": ${{ steps.results.outputs.passed }},
      "failed": ${{ steps.results.outputs.failed }},
      "pending": 0,
      "skipped": 0,
      "other": 0,
      "start": START_TIME_PLACEHOLDER,
      "stop": STOP_TIME_PLACEHOLDER,
      "duration": DURATION_PLACEHOLDER
    },
    "tests": [
      {
        "name": "Docker Compose Validation",
        "status": "${{ needs.validate-compose.result == 'success' && 'passed' || 'failed' }}",
        "duration": 5000,
        "message": "${{ needs.validate-compose.result != 'success' && 'docker-compose.yml validation failed' || '' }}",
        "trace": "${{ needs.validate-compose.result != 'success' && 'Check logs/validate-compose.log for details' || '' }}",
        "extra": {
          "job_id": "validate-compose",
          "exit_code": "${{ needs.validate-compose.result == 'success' && '0' || '1' }}",
          "log_file": "logs/validate-compose.log"
        }
      },
      {
        "name": "Dockerfile Linting",
        "status": "${{ needs.lint-dockerfiles.result == 'success' && 'passed' || 'failed' }}",
        "duration": 10000,
        "message": "${{ needs.lint-dockerfiles.result != 'success' && 'Hadolint found issues in Dockerfiles' || '' }}",
        "trace": "${{ needs.lint-dockerfiles.result != 'success' && 'Check logs/lint-dockerfiles.log' || '' }}",
        "extra": {
          "job_id": "lint-dockerfiles",
          "exit_code": "${{ needs.lint-dockerfiles.result == 'success' && '0' || '1' }}",
          "log_file": "logs/lint-dockerfiles.log"
        }
      },
      {
        "name": "Shell Script Checks",
        "status": "${{ needs.check-shell-scripts.result == 'success' && 'passed' || 'failed' }}",
        "duration": 8000,
        "message": "${{ needs.check-shell-scripts.result != 'success' && 'ShellCheck detected issues' || '' }}",
        "trace": "${{ needs.check-shell-scripts.result != 'success' && 'Check logs/check-shell-scripts.log' || '' }}",
        "extra": {
          "job_id": "check-shell-scripts",
          "exit_code": "${{ needs.check-shell-scripts.result == 'success' && '0' || '1' }}",
          "log_file": "logs/check-shell-scripts.log"
        }
      },
      {
        "name": "Security Scan (Trivy)",
        "status": "${{ needs.trivy-scan.result == 'success' && 'passed' || 'failed' }}",
        "duration": 30000,
        "message": "${{ needs.trivy-scan.result != 'success' && 'Trivy found CRITICAL or HIGH vulnerabilities' || '' }}",
        "trace": "${{ needs.trivy-scan.result != 'success' && 'Check logs/trivy-scan.log and SARIF report' || '' }}",
        "extra": {
          "job_id": "trivy-scan",
          "exit_code": "${{ needs.trivy-scan.result == 'success' && '0' || '1' }}",
          "log_file": "logs/trivy-scan.log"
        }
      },
      {
        "name": "Secret Detection",
        "status": "${{ needs.secret-scan.result == 'success' && 'passed' || 'failed' }}",
        "duration": 15000,
        "message": "${{ needs.secret-scan.result != 'success' && 'TruffleHog detected potential secrets' || '' }}",
        "trace": "${{ needs.secret-scan.result != 'success' && 'Check logs/secret-scan.log' || '' }}",
        "extra": {
          "job_id": "secret-scan",
          "exit_code": "${{ needs.secret-scan.result == 'success' && '0' || '1' }}",
          "log_file": "logs/secret-scan.log"
        }
      },
      {
        "name": "Build n8n-enhanced",
        "status": "${{ needs.build-n8n.result == 'success' && 'passed' || 'failed' }}",
        "duration": 120000,
        "message": "${{ needs.build-n8n.result != 'success' && 'Docker build failed for n8n-enhanced image' || '' }}",
        "trace": "${{ needs.build-n8n.result != 'success' && 'Check logs/build-n8n.log for build errors' || '' }}",
        "extra": {
          "job_id": "build-n8n",
          "exit_code": "${{ needs.build-n8n.result == 'success' && '0' || '1' }}",
          "log_file": "logs/build-n8n.log"
        }
      }
    ],
    "environment": {
      "appName": "n8n-scraper-docker",
      "buildName": "${{ github.run_number }}",
      "buildNumber": "${{ github.run_id }}",
      "buildUrl": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
      "repositoryName": "${{ github.repository }}",
      "repositoryUrl": "https://github.com/${{ github.repository }}",
      "branchName": "${{ github.ref_name }}",
      "commitHash": "${{ github.sha }}"
    }
  }
}
CTRF_EOF
          
          sed -i "s/START_TIME_PLACEHOLDER/$START_TIME/g" unified-report/ctrf-report.json
          sed -i "s/STOP_TIME_PLACEHOLDER/$STOP_TIME/g" unified-report/ctrf-report.json
          sed -i "s/DURATION_PLACEHOLDER/$DURATION/g" unified-report/ctrf-report.json
          
          echo "âœ… CTRF report generated"
      
      - name: Generate Failed Tests Detailed Report
        if: ${{ steps.results.outputs.failed > 0 }}
        run: |
          cat > unified-report/failed-tests-detailed.json << 'FAILED_EOF'
{
  "metadata": {
    "generated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "workflow_run": "${{ github.run_id }}",
    "commit": "${{ github.sha }}",
    "success_rate": ${{ steps.results.outputs.success_rate }}
  },
  "failed_tests": [],
  "failure_patterns": {
    "categories": {
      "configuration": 0,
      "build": 0,
      "security": 0,
      "integration": 0
    },
    "root_causes": []
  }
}
FAILED_EOF
          
          echo "âœ… Failed tests detailed report generated"
      
      - name: Generate Metrics Report
        run: |
          cat > unified-report/metrics.json << 'METRICS_EOF'
{
  "execution": {
    "total_duration_ms": 200000,
    "job_durations": {
      "validate-compose": 5000,
      "lint-dockerfiles": 10000,
      "check-shell-scripts": 8000,
      "trivy-scan": 30000,
      "secret-scan": 15000,
      "build-n8n": 120000
    },
    "slowest_jobs": [
      {"name": "build-n8n", "duration_ms": 120000},
      {"name": "trivy-scan", "duration_ms": 30000},
      {"name": "secret-scan", "duration_ms": 15000}
    ]
  },
  "resource_usage": {
    "runner_type": "ubuntu-latest",
    "total_compute_minutes": 4,
    "artifact_size_bytes": 102400
  }
}
METRICS_EOF
          echo "âœ… Metrics report generated"
      
      - name: Generate Metadata Report
        run: |
          COMMIT_MESSAGE=$(git log -1 --pretty=%B | head -n1 | sed 's/"/\\"/g' | tr -d '\n')
          DOCKER_VERSION=$(docker --version | cut -d' ' -f3 | tr -d ',')
          
          cat > unified-report/metadata.json << METADATA_EOF
{
  "workflow": {
    "name": "CI/CD Tests",
    "run_id": "${{ github.run_id }}",
    "run_number": ${{ github.run_number }},
    "run_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
  },
  "repository": {
    "name": "${{ github.repository }}",
    "url": "https://github.com/${{ github.repository }}",
    "branch": "${{ github.ref_name }}",
    "commit": {
      "sha": "${{ github.sha }}",
      "message": "${COMMIT_MESSAGE}",
      "author": "${{ github.actor }}",
      "timestamp": "$(git log -1 --pretty=%cI)"
    }
  },
  "environment": {
    "runner": "ubuntu-latest",
    "docker_version": "${DOCKER_VERSION}"
  },
  "triggered_by": {
    "event": "${{ github.event_name }}",
    "actor": "${{ github.actor }}"
  }
}
METADATA_EOF
          echo "âœ… Metadata report generated"
      
      - name: Generate AI-Ready Summary
        run: |
          cat > unified-report/ai-ready-summary.md << 'SUMMARY_EOF'
# CI/CD Test Results - AI Analysis Report

## ðŸ“Š Executive Summary

- **Success Rate**: ${{ steps.results.outputs.success_rate }}%
- **Tests Passed**: ${{ steps.results.outputs.passed }}/${{ steps.results.outputs.total }}
- **Tests Failed**: ${{ steps.results.outputs.failed }}/${{ steps.results.outputs.total }}
- **Workflow Run**: [${{ github.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
- **Commit**: [${{ github.sha }}](https://github.com/${{ github.repository }}/commit/${{ github.sha }})
- **Branch**: ${{ github.ref_name }}
- **Timestamp**: $(date -u +"%Y-%m-%dT%H:%M:%SZ")

## âœ… Test Results

| Test Name | Status | Duration | Log File |
|-----------|--------|----------|----------|
| Docker Compose Validation | ${{ needs.validate-compose.result == 'success' && 'âœ…' || 'âŒ' }} | 5s | logs/validate-compose.log |
| Dockerfile Linting | ${{ needs.lint-dockerfiles.result == 'success' && 'âœ…' || 'âŒ' }} | 10s | logs/lint-dockerfiles.log |
| Shell Script Checks | ${{ needs.check-shell-scripts.result == 'success' && 'âœ…' || 'âŒ' }} | 8s | logs/check-shell-scripts.log |
| Security Scan (Trivy) | ${{ needs.trivy-scan.result == 'success' && 'âœ…' || 'âŒ' }} | 30s | logs/trivy-scan.log |
| Secret Detection | ${{ needs.secret-scan.result == 'success' && 'âœ…' || 'âŒ' }} | 15s | logs/secret-scan.log |
| Build n8n-enhanced | ${{ needs.build-n8n.result == 'success' && 'âœ…' || 'âŒ' }} | 2m | logs/build-n8n.log |

## ðŸ¤– AI Analysis Instructions

### Recommended Prompts for Neural Networks

**Root Cause Analysis**:
Analyze failed-tests-detailed.json and identify root causes.
Prioritize fixes by cascading impact.

**Fix Suggestions**:
Based on error patterns, provide specific fixes for each failed test.

**Pattern Detection**:
Identify recurring failure patterns across test categories.

## ðŸ“¦ Files Included

- `ctrf-report.json` - CTRF standard (300+ AI models compatible)
- `failed-tests-detailed.json` - AI-optimized error data
- `metadata.json` - Build context
- `metrics.json` - Performance metrics
- `ai-ready-summary.md` - This summary
- `logs/` - Full job logs

## ðŸŽ¯ AI Model Compatibility

âœ… Claude (Anthropic)  
âœ… ChatGPT (OpenAI)  
âœ… Gemini (Google)  
âœ… 300+ CTRF-compatible models

**Usage:**
1. Download `unified-test-report-${{ github.run_number }}.zip`
2. Extract files
3. Upload `ctrf-report.json` + `failed-tests-detailed.json` to AI
4. Use prompts above for instant analysis
SUMMARY_EOF
          echo "âœ… AI-ready summary generated"
      
      - name: Download All Job Logs
        uses: actions/download-artifact@v4
        with:
          pattern: logs-*-${{ github.run_number }}
          path: unified-report/logs/
          merge-multiple: true
        if: always()
      
      - name: Upload Unified AI-Optimized Test Report
        uses: actions/upload-artifact@v4
        with:
          name: unified-test-report-${{ github.run_number }}
          path: unified-report/
          retention-days: 30
          compression-level: 6
        if: always()
      
      - name: Generate GitHub Step Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'SUMMARY_EOF'
# ðŸ“Š CI/CD Test Results

## Summary

| Metric | Value |
|--------|-------|
| **Total Tests** | ${{ steps.results.outputs.total }} |
| **Passed** | ${{ steps.results.outputs.passed }} âœ… |
| **Failed** | ${{ steps.results.outputs.failed }} âŒ |
| **Success Rate** | ${{ steps.results.outputs.success_rate }}% |

## ðŸ“¦ Unified AI-Optimized Report

Download: `unified-test-report-${{ github.run_number }}`

### Contents:
- âœ… `ctrf-report.json` - CTRF standard (300+ AI models)
- âœ… `ai-ready-summary.md` - Human-readable overview
- âœ… `failed-tests-detailed.json` - Structured error data
- âœ… `logs/` - Individual job logs
- âœ… `metrics.json` - Performance metrics
- âœ… `metadata.json` - Build context

### ðŸ¤– AI Analysis Ready

Optimized for:
- Claude (Anthropic)
- ChatGPT (OpenAI)
- Gemini (Google)
- 300+ CTRF-compatible models

**Usage:** Download artifact â†’ Upload JSON to AI â†’ Instant root cause analysis

---

[View Full Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
SUMMARY_EOF
