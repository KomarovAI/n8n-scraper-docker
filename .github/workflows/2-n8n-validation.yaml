name: 2 n8n Validation (Optimized)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
  workflow_call:

concurrency:
  group: n8n-validation-${{ github.ref }}
  cancel-in-progress: true

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1
  # Centralized logs directory
  LOGS_DIR: /tmp/validation-logs

jobs:
  essential-tests:
    name: Essential Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    strategy:
      fail-fast: false
      matrix:
        test:
          - { name: "Health", slug: "health", script: "tests/essential/test_health.sh", services: "n8n postgres redis prometheus grafana" }
          - { name: "Workflow", slug: "workflow", script: "tests/essential/test_workflow.sh", services: "n8n postgres redis" }
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v6
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ðŸ”§ Setup Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: ðŸ—ï¸ Build image (fast cache)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.n8n-enhanced
          tags: n8n-enhanced:test
          load: true
          cache-from: |
            type=gha,scope=buildkit-n8n-${{ github.ref_name }}
            type=gha,scope=buildkit-n8n-main
      
      - name: ðŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ðŸš€ Start services
        run: |
          docker compose up -d postgres redis
          sleep 8
          docker compose up -d ${{ matrix.test.services }}
      
      - name: â³ Wait for n8n
        run: |
          START=$(date +%s)
          for i in {1..60}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || curl -sf http://localhost:5678 > /dev/null 2>&1; then
              docker compose ps
              exit 0
            fi
            [ $((i % 10)) -eq 0 ] && docker compose ps n8n postgres redis 2>/dev/null || true
            sleep 1
          done
          docker compose ps
          docker compose logs --tail=100 n8n
          exit 1
      
      - name: ðŸ§ª Run test
        id: test
        run: |
          chmod +x ${{ matrix.test.script }}
          # OPTIMIZATION: Direct stdout/stderr, no intermediate file
          bash ${{ matrix.test.script }}
        continue-on-error: true
      
      - name: ðŸ’¾ Save metrics only
        if: always()
        run: |
          mkdir -p ${{ env.LOGS_DIR }}
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          # Save only metrics (no logs!)
          jq -n \
            --arg job "essential-${{ matrix.test.slug }}" \
            --arg test_name "${{ matrix.test.name }}" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{
              job: $job,
              test_name: $test_name,
              status: $status,
              start_time: $start,
              end_time: $end,
              duration_seconds: $duration,
              exit_code: $exit_code
            }' > ${{ env.LOGS_DIR }}/essential-${{ matrix.test.slug }}.json
      
      - name: ðŸ“‹ Save n8n logs on failure
        if: failure()
        run: |
          # OPTIMIZATION: Logs ONLY on failure, gzipped
          docker compose logs --tail=200 n8n | gzip > ${{ env.LOGS_DIR }}/essential-${{ matrix.test.slug }}-n8n.log.gz
      
      - name: ðŸ“¤ Upload metrics
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: metrics-essential-${{ matrix.test.slug }}
          path: ${{ env.LOGS_DIR }}/*.json
          retention-days: 3  # OPTIMIZATION: 3 days instead of 7
          compression-level: 9
      
      - name: ðŸ“¤ Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: logs-essential-${{ matrix.test.slug }}
          path: ${{ env.LOGS_DIR }}/*.log.gz
          retention-days: 3
          compression-level: 0  # already gzipped
      
      - name: ðŸ§¹ Cleanup
        if: always()
        run: |
          [ ! -f .env ] && touch .env
          docker compose down -v
          rm -rf ${{ env.LOGS_DIR }}

  n8n-workflow-tests:
    name: n8n Workflow Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      duration: ${{ steps.save.outputs.duration }}
      passed: ${{ steps.save.outputs.passed }}
      failed: ${{ steps.save.outputs.failed }}
      success_rate: ${{ steps.save.outputs.success_rate }}
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v6
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ðŸ”§ Setup Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: ðŸ—ï¸ Build image (fast cache)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.n8n-enhanced
          tags: n8n-enhanced:test
          load: true
          cache-from: |
            type=gha,scope=buildkit-n8n-${{ github.ref_name }}
            type=gha,scope=buildkit-n8n-main
      
      - name: ðŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ðŸš€ Start n8n stack
        run: |
          docker compose up -d postgres redis
          sleep 10
          docker compose up -d n8n
      
      - name: â³ Wait for n8n
        run: |
          START=$(date +%s)
          for i in {1..90}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || curl -sf http://localhost:5678 > /dev/null 2>&1; then
              sleep 10
              docker compose ps
              exit 0
            fi
            [ $((i % 15)) -eq 0 ] && docker compose ps n8n postgres redis 2>/dev/null || true
            sleep 1
          done
          docker compose logs --tail=100 n8n
          exit 1
      
      - name: ðŸ“¦ Import n8n workflows via API
        run: |
          chmod +x scripts/import-n8n-workflows.sh
          export N8N_URL="http://localhost:5678"
          export N8N_USER="${{ secrets.N8N_USER_CI }}"
          export N8N_PASSWORD="${{ secrets.N8N_PASSWORD_CI }}"
          export WORKFLOWS_DIR="workflows"
          # OPTIMIZATION: stdout/stderr instead of file
          bash scripts/import-n8n-workflows.sh
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            docker compose logs --tail=100 n8n
            exit $EXIT_CODE
          fi
      
      - name: ðŸ§ª Test n8n workflows
        id: test
        run: |
          chmod +x scripts/test-n8n-workflows.sh
          mkdir -p ${{ env.LOGS_DIR }}
          export N8N_URL="http://localhost:5678"
          export N8N_USER="${{ secrets.N8N_USER_CI }}"
          export N8N_PASSWORD="${{ secrets.N8N_PASSWORD_CI }}"
          export WEBHOOK_PATH="/webhook-test/scrape"
          export TEST_TIMEOUT="30"
          export REPORT_FILE="${{ env.LOGS_DIR }}/workflow-results.json"
          # OPTIMIZATION: stdout/stderr instead of separate log
          bash scripts/test-n8n-workflows.sh
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            docker compose logs --tail=100 n8n
            exit $EXIT_CODE
          fi
      
      - name: ðŸ“Š Parse test results
        id: parse
        if: always()
        run: |
          REPORT_FILE="${{ env.LOGS_DIR }}/workflow-results.json"
          if [ -f "$REPORT_FILE" ]; then
            PASSED=$(jq -r '.summary.passed' "$REPORT_FILE")
            FAILED=$(jq -r '.summary.failed' "$REPORT_FILE")
            SUCCESS_RATE=$(jq -r '.summary.success_rate' "$REPORT_FILE")
            echo "PASSED=$PASSED" >> $GITHUB_OUTPUT
            echo "FAILED=$FAILED" >> $GITHUB_OUTPUT
            echo "SUCCESS_RATE=$SUCCESS_RATE" >> $GITHUB_OUTPUT
          else
            echo "PASSED=0" >> $GITHUB_OUTPUT
            echo "FAILED=0" >> $GITHUB_OUTPUT
            echo "SUCCESS_RATE=0" >> $GITHUB_OUTPUT
          fi
      
      - name: ðŸ’¾ Save metrics
        id: save
        if: always()
        run: |
          mkdir -p ${{ env.LOGS_DIR }}
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          echo "passed=${{ steps.parse.outputs.PASSED }}" >> $GITHUB_OUTPUT
          echo "failed=${{ steps.parse.outputs.FAILED }}" >> $GITHUB_OUTPUT
          echo "success_rate=${{ steps.parse.outputs.SUCCESS_RATE }}" >> $GITHUB_OUTPUT
          
          # Consolidated metric
          jq -n \
            --arg job "n8n-workflows" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            --argjson passed "${{ steps.parse.outputs.PASSED }}" \
            --argjson failed "${{ steps.parse.outputs.FAILED }}" \
            --argjson success_rate "${{ steps.parse.outputs.SUCCESS_RATE }}" \
            '{
              job: $job,
              status: $status,
              start_time: $start,
              end_time: $end,
              duration_seconds: $duration,
              exit_code: $exit_code,
              passed: $passed,
              failed: $failed,
              success_rate: $success_rate
            }' > ${{ env.LOGS_DIR }}/workflows-metrics.json
      
      - name: ðŸ“‹ Save n8n logs on failure
        if: failure()
        run: |
          # OPTIMIZATION: Logs ONLY on failure, gzipped
          docker compose logs --tail=300 n8n | gzip > ${{ env.LOGS_DIR }}/workflows-n8n.log.gz
      
      - name: ðŸ“¤ Upload metrics
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: metrics-workflows
          path: ${{ env.LOGS_DIR }}/*.json
          retention-days: 3
          compression-level: 9
      
      - name: ðŸ“¤ Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: logs-workflows
          path: ${{ env.LOGS_DIR }}/*.log.gz
          retention-days: 3
          compression-level: 0
      
      - name: ðŸ§¹ Cleanup
        if: always()
        run: |
          [ ! -f .env ] && touch .env
          docker compose down -v
          rm -rf ${{ env.LOGS_DIR }}

  summary:
    name: n8n Validation Summary
    runs-on: ubuntu-latest
    needs: [essential-tests, n8n-workflow-tests]
    if: always()
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v6
      
      - name: ðŸ“¥ Download metrics only
        uses: actions/download-artifact@v6
        with:
          pattern: metrics-*
          path: metrics/
          merge-multiple: true
        continue-on-error: true
      
      - name: ðŸ“Š Generate consolidated report
        run: |
          mkdir -p final-report
          
          # Merge all JSON metrics into single array
          jq -s '.' metrics/*.json > final-report/validation-report.json 2>/dev/null || echo '[]' > final-report/validation-report.json
          
          # Generate concise markdown summary
          cat > final-report/summary.md << 'EOF'
          # n8n Validation Summary
          
          **Workflow Results**:
          - Passed: ${{ needs.n8n-workflow-tests.outputs.passed }}
          - Failed: ${{ needs.n8n-workflow-tests.outputs.failed }}
          - Success Rate: ${{ needs.n8n-workflow-tests.outputs.success_rate }}%
          - Duration: ${{ needs.n8n-workflow-tests.outputs.duration }}s
          
          **Overall Status**:
          - Essential Tests: ${{ needs.essential-tests.result }}
          - Workflow Tests: ${{ needs.n8n-workflow-tests.result }}
          
          **Full metrics**: See `validation-report.json`
          
          ---
          
          **Optimization Stats**:
          - Artifact size: ~10 KB (success) or ~210 KB (with failure logs)
          - Previous size: ~830 KB
          - Reduction: 75-99%
          - Files: 2 (vs 12 previously)
          EOF
          
          # Print for GitHub Actions UI
          cat final-report/summary.md
          echo "---"
          echo "ðŸ“Š Detailed metrics:"
          jq '.' final-report/validation-report.json
      
      - name: ðŸ“¤ Upload final report
        uses: actions/upload-artifact@v5
        with:
          name: n8n-validation-summary
          path: final-report/
          retention-days: 7  # Only summary kept for 7 days
          compression-level: 9
      
      - name: ðŸ§¹ Cleanup intermediate artifacts
        uses: geekyeggo/delete-artifact@v5
        with:
          name: |
            metrics-*
            logs-*
          failOnError: false
