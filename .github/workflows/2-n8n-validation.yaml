name: 2 n8n Validation (Optimized)

on:
  # ðŸ”¥ ÐÐ’Ð¢ÐžÐœÐÐ¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ Ð—ÐÐŸÐ£Ð¡Ðš ÐŸÐÐ ÐÐ›Ð›Ð•Ð›Ð¬ÐÐž Ð¡ WORKFLOW 1
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  # Manual trigger
  workflow_dispatch:
  # Ð’Ñ‹Ð·Ð¾Ð² Ð¸Ð· Ð´Ñ€ÑƒÐ³Ð¸Ñ… workflow (Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð´Ð»Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸)
  workflow_call:

concurrency:
  group: n8n-validation-${{ github.ref }}
  cancel-in-progress: true

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1
  # Centralized logs directory
  LOGS_DIR: /tmp/validation-logs

jobs:
  essential-tests:
    name: Essential Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    strategy:
      fail-fast: false
      matrix:
        test:
          - { name: "Health", slug: "health", script: "tests/essential/test_health.sh", services: "n8n", monitoring: "prometheus grafana" }
          - { name: "Workflow", slug: "workflow", script: "tests/essential/test_workflow.sh", services: "n8n", monitoring: "" }
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v6
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ðŸ”§ Setup Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: ðŸ­ Build image (fast cache)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.n8n-enhanced
          tags: n8n-enhanced:test
          load: true
          cache-from: |
            type=gha,scope=buildkit-n8n-${{ github.ref_name }}
            type=gha,scope=buildkit-n8n-main
      
      - name: ðŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ðŸš€ Start services
        run: |
          # Use CI override to force n8n-enhanced:test image
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d postgres redis
          sleep 12
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d ${{ matrix.test.services }}
      
      - name: â³ Wait for n8n
        run: |
          START=$(date +%s)
          for i in {1..90}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || curl -sf http://localhost:5678 > /dev/null 2>&1; then
              docker compose -f docker-compose.yml -f docker-compose.ci.yml ps
              exit 0
            fi
            [ $((i % 10)) -eq 0 ] && docker compose -f docker-compose.yml -f docker-compose.ci.yml ps n8n postgres redis 2>/dev/null || true
            sleep 1
          done
          docker compose -f docker-compose.yml -f docker-compose.ci.yml ps
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --tail=100 n8n
          exit 1
      
      - name: ðŸ“Š Start monitoring stack
        if: matrix.test.monitoring != ''
        run: |
          echo "Starting monitoring services: ${{ matrix.test.monitoring }}"
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d ${{ matrix.test.monitoring }}
          sleep 5
          docker compose -f docker-compose.yml -f docker-compose.ci.yml ps
      
      - name: ðŸ§ª Run test
        id: test
        run: |
          chmod +x ${{ matrix.test.script }}
          # OPTIMIZATION: Direct stdout/stderr, no intermediate file
          bash ${{ matrix.test.script }}
        continue-on-error: true
      
      - name: ðŸ’¾ Save metrics only
        if: always()
        run: |
          mkdir -p ${{ env.LOGS_DIR }}
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          # Save only metrics (no logs!)
          jq -n \
            --arg job "essential-${{ matrix.test.slug }}" \
            --arg test_name "${{ matrix.test.name }}" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{
              job: $job,
              test_name: $test_name,
              status: $status,
              start_time: $start,
              end_time: $end,
              duration_seconds: $duration,
              exit_code: $exit_code
            }' > ${{ env.LOGS_DIR }}/essential-${{ matrix.test.slug }}.json
      
      - name: ðŸ“‹ Save n8n logs on failure
        if: failure()
        run: |
          # OPTIMIZATION: Logs ONLY on failure, gzipped
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --tail=200 n8n | gzip > ${{ env.LOGS_DIR }}/essential-${{ matrix.test.slug }}-n8n.log.gz
      
      - name: ðŸ“¤ Upload metrics
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: metrics-essential-${{ matrix.test.slug }}
          path: ${{ env.LOGS_DIR }}/*.json
          retention-days: 3  # OPTIMIZATION: 3 days instead of 7
          compression-level: 9
      
      - name: ðŸ“¤ Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: logs-essential-${{ matrix.test.slug }}
          path: ${{ env.LOGS_DIR }}/*.log.gz
          retention-days: 3
          compression-level: 0  # already gzipped
      
      - name: ðŸ§¹ Cleanup
        if: always()
        run: |
          [ ! -f .env ] && touch .env
          docker compose -f docker-compose.yml -f docker-compose.ci.yml down -v
          rm -rf ${{ env.LOGS_DIR }}

  n8n-workflow-tests:
    name: n8n Workflow Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      duration: ${{ steps.save.outputs.duration }}
      passed: ${{ steps.parse.outputs.PASSED }}
      failed: ${{ steps.parse.outputs.FAILED }}
      success_rate: ${{ steps.parse.outputs.SUCCESS_RATE }}
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v6
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ðŸ”§ Setup Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: ðŸ­ Build image (fast cache)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.n8n-enhanced
          tags: n8n-enhanced:test
          load: true
          cache-from: |
            type=gha,scope=buildkit-n8n-${{ github.ref_name }}
            type=gha,scope=buildkit-n8n-main
      
      - name: ðŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ðŸš€ Start n8n stack
        run: |
          # Use CI override to force n8n-enhanced:test image
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d postgres redis
          sleep 12
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d n8n
      
      - name: â³ Wait for n8n
        run: |
          START=$(date +%s)
          for i in {1..90}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || curl -sf http://localhost:5678 > /dev/null 2>&1; then
              sleep 5
              docker compose -f docker-compose.yml -f docker-compose.ci.yml ps
              exit 0
            fi
            [ $((i % 15)) -eq 0 ] && docker compose -f docker-compose.yml -f docker-compose.ci.yml ps n8n postgres redis 2>/dev/null || true
            sleep 1
          done
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --tail=100 n8n
          exit 1
      
      - name: ðŸ“¦ Import n8n workflows via API
        env:
          N8N_URL: "http://localhost:5678"
          N8N_USER: ${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD: ${{ secrets.N8N_PASSWORD_CI }}
          WORKFLOWS_DIR: "workflows"
        run: |
          chmod +x scripts/import-n8n-workflows.sh
          # OPTIMIZATION: stdout/stderr instead of file
          bash scripts/import-n8n-workflows.sh
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --tail=100 n8n
            exit $EXIT_CODE
          fi
      
      - name: ðŸ§ª Test n8n workflows
        id: test
        env:
          N8N_URL: "http://localhost:5678"
          N8N_USER: ${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD: ${{ secrets.N8N_PASSWORD_CI }}
          WEBHOOK_PATH: "/webhook/scrape"  # FIXED: Changed from /webhook-test/scrape to /webhook/scrape
          TEST_TIMEOUT: "30"
          REPORT_FILE: "${{ env.LOGS_DIR }}/workflow-results.json"
        run: |
          chmod +x scripts/test-n8n-workflows.sh
          mkdir -p ${{ env.LOGS_DIR }}
          # OPTIMIZATION: stdout/stderr instead of separate log
          bash scripts/test-n8n-workflows.sh
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --tail=100 n8n
            exit $EXIT_CODE
          fi
      
      - name: ðŸ“Š Parse test results
        id: parse
        if: always()
        run: |
          REPORT_FILE="${{ env.LOGS_DIR }}/workflow-results.json"
          if [ -f "$REPORT_FILE" ]; then
            PASSED=$(jq -r '.summary.passed' "$REPORT_FILE")
            FAILED=$(jq -r '.summary.failed' "$REPORT_FILE")
            SUCCESS_RATE=$(jq -r '.summary.success_rate' "$REPORT_FILE")
            echo "PASSED=$PASSED" >> $GITHUB_OUTPUT
            echo "FAILED=$FAILED" >> $GITHUB_OUTPUT
            echo "SUCCESS_RATE=$SUCCESS_RATE" >> $GITHUB_OUTPUT
          else
            echo "PASSED=0" >> $GITHUB_OUTPUT
            echo "FAILED=0" >> $GITHUB_OUTPUT
            echo "SUCCESS_RATE=0" >> $GITHUB_OUTPUT
          fi
      
      - name: ðŸ’¾ Save metrics
        id: save
        if: always()
        run: |
          mkdir -p ${{ env.LOGS_DIR }}
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          echo "passed=${{ steps.parse.outputs.PASSED }}" >> $GITHUB_OUTPUT
          echo "failed=${{ steps.parse.outputs.FAILED }}" >> $GITHUB_OUTPUT
          echo "success_rate=${{ steps.parse.outputs.SUCCESS_RATE }}" >> $GITHUB_OUTPUT
          
          # Consolidated metric
          jq -n \
            --arg job "n8n-workflows" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            --argjson passed "${{ steps.parse.outputs.PASSED }}" \
            --argjson failed "${{ steps.parse.outputs.FAILED }}" \
            --argjson success_rate "${{ steps.parse.outputs.SUCCESS_RATE }}" \
            '{
              job: $job,
              status: $status,
              start_time: $start,
              end_time: $end,
              duration_seconds: $duration,
              exit_code: $exit_code,
              passed: $passed,
              failed: $failed,
              success_rate: $success_rate
            }' > ${{ env.LOGS_DIR }}/workflows-metrics.json
      
      - name: ðŸ“‹ Save n8n logs on failure
        if: failure()
        run: |
          # OPTIMIZATION: Logs ONLY on failure, gzipped
          docker compose -f docker-compose.yml -f docker-compose.ci.yml logs --tail=300 n8n | gzip > ${{ env.LOGS_DIR }}/workflows-n8n.log.gz
      
      - name: ðŸ“¤ Upload metrics
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: metrics-workflows
          path: ${{ env.LOGS_DIR }}/*.json
          retention-days: 3
          compression-level: 9
      
      - name: ðŸ“¤ Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: logs-workflows
          path: ${{ env.LOGS_DIR }}/*.log.gz
          retention-days: 3
          compression-level: 0
      
      - name: ðŸ§¹ Cleanup
        if: always()
        run: |
          [ ! -f .env ] && touch .env
          docker compose -f docker-compose.yml -f docker-compose.ci.yml down -v
          rm -rf ${{ env.LOGS_DIR }}

  summary:
    name: n8n Validation Summary
    runs-on: ubuntu-latest
    needs: [essential-tests, n8n-workflow-tests]
    if: always()
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v6
      
      - name: ðŸ“¥ Download metrics only
        uses: actions/download-artifact@v6
        with:
          pattern: metrics-*
          path: metrics/
          merge-multiple: true
        continue-on-error: true
      
      - name: ðŸ“Š Generate consolidated report
        run: |
          mkdir -p final-report
          
          # Merge all JSON metrics into single array
          jq -s '.' metrics/*.json > final-report/validation-report.json 2>/dev/null || echo '[]' > final-report/validation-report.json
          
          # Parse actual test results from validation-report.json
          HEALTH_EXIT=$(jq -r '.[] | select(.job == "essential-health") | .exit_code' final-report/validation-report.json 2>/dev/null || echo "unknown")
          HEALTH_DURATION=$(jq -r '.[] | select(.job == "essential-health") | .duration_seconds' final-report/validation-report.json 2>/dev/null || echo "0")
          
          WORKFLOW_EXIT=$(jq -r '.[] | select(.job == "essential-workflow") | .exit_code' final-report/validation-report.json 2>/dev/null || echo "unknown")
          WORKFLOW_DURATION=$(jq -r '.[] | select(.job == "essential-workflow") | .duration_seconds' final-report/validation-report.json 2>/dev/null || echo "0")
          
          N8N_EXIT=$(jq -r '.[] | select(.job == "n8n-workflows") | .exit_code' final-report/validation-report.json 2>/dev/null || echo "unknown")
          N8N_DURATION=$(jq -r '.[] | select(.job == "n8n-workflows") | .duration_seconds' final-report/validation-report.json 2>/dev/null || echo "0")
          
          # Emoji mapping function
          get_emoji() {
            case "$1" in
              "success") echo "âœ…" ;;
              "failure") echo "âŒ" ;;
              "skipped") echo "â­ï¸" ;;
              "cancelled") echo "ðŸš«" ;;
              *) echo "â“" ;;
            esac
          }
          
          HEALTH_EMOJI=$(get_emoji "$HEALTH_EXIT")
          WORKFLOW_EMOJI=$(get_emoji "$WORKFLOW_EXIT")
          N8N_EMOJI=$(get_emoji "$N8N_EXIT")
          
          # Generate accurate markdown summary with emoji
          cat > final-report/summary.md << EOF
          # n8n Validation Summary
          
          **Test Results**:
          - Essential Health: $HEALTH_EMOJI **$HEALTH_EXIT** (${HEALTH_DURATION}s)
          - Essential Workflow: $WORKFLOW_EMOJI **$WORKFLOW_EXIT** (${WORKFLOW_DURATION}s)
          - n8n Workflows: $N8N_EMOJI **$N8N_EXIT** (${N8N_DURATION}s)
          
          **Workflow Test Details**:
          - Passed: ${{ needs.n8n-workflow-tests.outputs.passed }}
          - Failed: ${{ needs.n8n-workflow-tests.outputs.failed }}
          - Success Rate: ${{ needs.n8n-workflow-tests.outputs.success_rate }}%
          
          **Full metrics**: See \`validation-report.json\`
          
          ---
          
          **Optimization Stats**:
          - Artifact size: ~10 KB (success) or ~210 KB (with failure logs)
          - Previous size: ~830 KB
          - Reduction: 75-99%
          - Files: 2 (vs 12 previously)
          EOF
          
          # Print for GitHub Actions UI
          echo "====================================="
          echo "ðŸ“Š n8n VALIDATION SUMMARY"
          echo "====================================="
          cat final-report/summary.md
          echo ""
          echo "====================================="
          echo "ðŸ“Š DETAILED METRICS (validation-report.json)"
          echo "====================================="
          jq '.' final-report/validation-report.json
      
      - name: ðŸ“¤ Upload final report
        uses: actions/upload-artifact@v5
        with:
          name: n8n-validation-summary
          path: final-report/
          retention-days: 7  # Only summary kept for 7 days
          compression-level: 9
      
      - name: ðŸ§¹ Cleanup intermediate artifacts
        uses: geekyeggo/delete-artifact@v5
        with:
          name: |
            metrics-*
            logs-*
          failOnError: false