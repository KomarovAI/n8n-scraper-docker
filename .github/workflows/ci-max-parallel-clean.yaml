name: ğŸš€ CI/CD Maximum Parallel (Clean)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

concurrency:
  group: ci-max-parallel-${{ github.ref }}
  cancel-in-progress: true

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  fast-validation:
    name: âš¡ Fast Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      start_time: ${{ steps.timer.outputs.start_time }}
      duration: ${{ steps.save.outputs.duration }}
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ğŸ³ Setup Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            image=moby/buildkit:latest
            network=host
      
      - name: ğŸ”’ Security scan
        run: |
          echo "Scanning for secrets..."
          docker run --rm -v "$(pwd)":/path trufflesecurity/trufflehog:latest filesystem /path --only-verified --fail || echo "No verified secrets"
          echo "Scan complete"
        continue-on-error: true
      
      - name: ğŸ³ Build and export
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.n8n-enhanced
          tags: n8n-enhanced:test
          outputs: type=docker,dest=/tmp/n8n-enhanced.tar
          cache-from: |
            type=gha,scope=buildkit-n8n-${{ github.ref_name }}
            type=gha,scope=buildkit-n8n-main
          cache-to: type=gha,mode=max,scope=buildkit-n8n-${{ github.ref_name }}
          build-args: |
            BUILDKIT_INLINE_CACHE=1
      
      - name: ğŸ“¦ Compress image
        run: gzip -1 /tmp/n8n-enhanced.tar
      
      - name: ğŸ“¤ Upload image
        uses: actions/upload-artifact@v4
        with:
          name: n8n-enhanced-image
          path: /tmp/n8n-enhanced.tar.gz
          retention-days: 1
          compression-level: 0
      
      - name: ğŸ“Š Save metrics
        id: save
        if: always()
        run: |
          mkdir -p /tmp/logs
          
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          
          IMAGE_SIZE=$(stat -c%s /tmp/n8n-enhanced.tar.gz 2>/dev/null | awk '{print int($1/1024/1024)}' || echo 0)
          
          echo "Build completed in ${DURATION}s, image size: ${IMAGE_SIZE}MB" | tee /tmp/logs/fast-validation-test.log
          
          jq -n \
            --arg job "fast-validation" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "success" \
            --argjson image_size "$IMAGE_SIZE" \
            '{job: $job, status: $status, start_time: $start, end_time: $end, duration_seconds: $duration, exit_code: $exit_code, image_size_mb: $image_size}' \
            > /tmp/logs/fast-validation-metrics.json
      
      - name: ğŸ’¾ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: temp-logs-fast-validation
          path: /tmp/logs/
          retention-days: 1

  smoke-tests:
    name: ğŸ’¨ Smoke Test
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: fast-validation
    strategy:
      fail-fast: false
      matrix:
        test:
          - { name: "PostgreSQL", slug: "postgres", script: "tests/smoke/test_postgres_redis.sh", services: "postgres" }
          - { name: "Redis", slug: "redis", script: "tests/smoke/test_postgres_redis.sh", services: "redis" }
          - { name: "Tor", slug: "tor", script: "tests/smoke/test_tor.sh", services: "tor" }
          - { name: "Prometheus", slug: "prometheus", script: "tests/smoke/test_monitoring.sh", services: "prometheus" }
          - { name: "Grafana", slug: "grafana", script: "tests/smoke/test_monitoring.sh", services: "grafana" }
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ğŸ“¥ Download image
        uses: actions/download-artifact@v4
        with:
          name: n8n-enhanced-image
          path: /tmp
      
      - name: ğŸ“¦ Load image
        run: docker load < /tmp/n8n-enhanced.tar.gz
      
      - name: ğŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ğŸš€ Start service
        run: docker compose up -d ${{ matrix.test.services }}
      
      - name: â±ï¸ Wait
        run: |
          for i in {1..30}; do
            docker compose ps | grep -q "Up" && { echo "Ready"; sleep 5; break; }
            sleep 2
          done
      
      - name: ğŸ§ª Run test
        id: test
        run: |
          chmod +x ${{ matrix.test.script }} || true
          bash ${{ matrix.test.script }} 2>&1 | tee /tmp/smoke-${{ matrix.test.slug }}-test.log
        continue-on-error: true
      
      - name: ğŸ“Š Save metrics
        if: always()
        run: |
          mkdir -p /tmp/logs
          
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          cp /tmp/smoke-${{ matrix.test.slug }}-test.log /tmp/logs/ 2>/dev/null || echo "No output" > /tmp/logs/smoke-${{ matrix.test.slug }}-test.log
          
          jq -n \
            --arg job "smoke-${{ matrix.test.slug }}" \
            --arg test_name "${{ matrix.test.name }}" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{job: $job, test_name: $test_name, status: $status, start_time: $start, end_time: $end, duration_seconds: $duration, exit_code: $exit_code}' \
            > /tmp/logs/smoke-${{ matrix.test.slug }}-metrics.json
      
      - name: ğŸ’¾ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: temp-logs-smoke-${{ matrix.test.slug }}
          path: /tmp/logs/
          retention-days: 1
      
      - name: ğŸ§¹ Cleanup
        if: always()
        run: docker compose down -v

  essential-tests:
    name: ğŸ§ª Essential Test
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: fast-validation
    strategy:
      fail-fast: false
      matrix:
        test:
          - { name: "Health", slug: "health", script: "tests/essential/test_health.sh", services: "n8n postgres redis" }
          - { name: "Workflow", slug: "workflow", script: "tests/essential/test_workflow.sh", services: "n8n postgres redis" }
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ğŸ“¥ Download image
        uses: actions/download-artifact@v4
        with:
          name: n8n-enhanced-image
          path: /tmp
      
      - name: ğŸ“¦ Load image
        run: docker load < /tmp/n8n-enhanced.tar.gz
      
      - name: ğŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ğŸš€ Start services (parallel)
        run: |
          # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ postgres+redis ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ°
          docker compose up -d postgres redis
          echo "Waiting for database..."
          sleep 10
          
          # Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ n8n
          docker compose up -d n8n
          echo "n8n started, waiting for initialization..."
      
      - name: â±ï¸ Wait for n8n (max 3 min)
        run: |
          echo "âŒ› Waiting for n8n to start (max 180 seconds)..."
          START=$(date +%s)
          
          # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ»Ğ¾Ğ³Ğ¸ Ğ² Ñ„Ğ¾Ğ½Ğµ
          docker compose logs -f n8n &
          LOGS_PID=$!
          
          for i in {1..90}; do
            ELAPSED=$(($(date +%s) - START))
            
            # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¾Ğ±Ğ° endpoint'Ğ°
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || \
               curl -sf http://localhost:5678 > /dev/null 2>&1; then
              kill $LOGS_PID 2>/dev/null || true
              echo "âœ… n8n is ready after ${ELAPSED}s!"
              docker compose ps
              exit 0
            fi
            
            # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 30Ñ
            if [ $((i % 15)) -eq 0 ]; then
              echo "âŒ› Still waiting... (${ELAPSED}s elapsed)"
              docker compose ps n8n postgres redis
            fi
            
            sleep 2
          done
          
          # Timeout - Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºÑƒ
          kill $LOGS_PID 2>/dev/null || true
          echo "âŒ n8n failed to start after 180 seconds"
          echo "=== Container status ==="
          docker compose ps
          echo "=== n8n logs ==="
          docker compose logs --tail=50 n8n
          echo "=== PostgreSQL status ==="
          docker compose exec -T postgres pg_isready || true
          echo "=== Redis status ==="
          docker compose exec -T redis redis-cli ping || true
          exit 1
      
      - name: ğŸ§ª Run test
        id: test
        run: |
          chmod +x ${{ matrix.test.script }}
          bash ${{ matrix.test.script }} 2>&1 | tee /tmp/essential-${{ matrix.test.slug }}-test.log
        continue-on-error: true
      
      - name: ğŸ“Š Save metrics
        if: always()
        run: |
          mkdir -p /tmp/logs
          
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          cp /tmp/essential-${{ matrix.test.slug }}-test.log /tmp/logs/ 2>/dev/null || echo "No output" > /tmp/logs/essential-${{ matrix.test.slug }}-test.log
          docker compose logs n8n > /tmp/logs/essential-${{ matrix.test.slug }}-n8n.log 2>&1 || true
          
          jq -n \
            --arg job "essential-${{ matrix.test.slug }}" \
            --arg test_name "${{ matrix.test.name }}" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{job: $job, test_name: $test_name, status: $status, start_time: $start, end_time: $end, duration_seconds: $duration, exit_code: $exit_code}' \
            > /tmp/logs/essential-${{ matrix.test.slug }}-metrics.json
      
      - name: ğŸ’¾ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: temp-logs-essential-${{ matrix.test.slug }}
          path: /tmp/logs/
          retention-days: 1
      
      - name: ğŸ§¹ Cleanup
        if: always()
        run: docker compose down -v

  e2e-tests:
    name: ğŸ¯ E2E Test
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: fast-validation
    outputs:
      duration: ${{ steps.save.outputs.duration }}
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ğŸ³ Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: 'tests/e2e/package.json'
      
      - name: ğŸ“¥ Download image
        uses: actions/download-artifact@v4
        with:
          name: n8n-enhanced-image
          path: /tmp
      
      - name: ğŸ“¦ Load image
        run: docker load < /tmp/n8n-enhanced.tar.gz
      
      - name: ğŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ğŸš€ Start stack (parallel)
        run: |
          docker compose up -d postgres redis
          sleep 10
          docker compose up -d n8n
      
      - name: â±ï¸ Wait for n8n (max 3 min)
        run: |
          echo "âŒ› Waiting for n8n..."
          START=$(date +%s)
          
          for i in {1..90}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || \
               curl -sf http://localhost:5678 > /dev/null 2>&1; then
              ELAPSED=$(($(date +%s) - START))
              echo "âœ… n8n ready after ${ELAPSED}s"
              exit 0
            fi
            [ $((i % 15)) -eq 0 ] && echo "âŒ› Waiting... ($((i * 2))s)"
            sleep 2
          done
          
          echo "âŒ Timeout"
          docker compose logs --tail=50 n8n
          exit 1
      
      - name: ğŸ“¦ Install deps
        working-directory: tests/e2e
        run: npm install || echo "No package.json"
      
      - name: ğŸ¯ Run test
        id: test
        working-directory: tests/e2e
        run: |
          if [ -f "workflow-test.js" ]; then
            node workflow-test.js 2>&1 | tee /tmp/e2e-test.log
          else
            echo "No E2E test" | tee /tmp/e2e-test.log
          fi
        continue-on-error: true
      
      - name: ğŸ“Š Save metrics
        id: save
        if: always()
        run: |
          mkdir -p /tmp/logs
          
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          
          cp /tmp/e2e-test.log /tmp/logs/ 2>/dev/null || echo "No output" > /tmp/logs/e2e-test.log
          docker compose logs n8n > /tmp/logs/e2e-n8n.log 2>&1 || true
          
          jq -n \
            --arg job "e2e" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{job: $job, status: $status, start_time: $start, end_time: $end, duration_seconds: $duration, exit_code: $exit_code}' \
            > /tmp/logs/e2e-metrics.json
      
      - name: ğŸ’¾ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: temp-logs-e2e
          path: /tmp/logs/
          retention-days: 1
      
      - name: ğŸ§¹ Cleanup
        if: always()
        run: docker compose down -v

  n8n-integration:
    name: ğŸŒ Integration
    runs-on: ubuntu-latest
    timeout-minutes: 12
    needs: [smoke-tests, essential-tests]
    outputs:
      duration: ${{ steps.save.outputs.duration }}
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ğŸ“¥ Download image
        uses: actions/download-artifact@v4
        with:
          name: n8n-enhanced-image
          path: /tmp
      
      - name: ğŸ“¦ Load image
        run: docker load < /tmp/n8n-enhanced.tar.gz
      
      - name: ğŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ğŸš€ Start n8n (parallel)
        run: |
          docker compose up -d postgres redis
          sleep 10
          docker compose up -d n8n
      
      - name: ğŸ” Verify (max 3 min)
        run: |
          echo "âŒ› Verifying n8n..."
          START=$(date +%s)
          
          for i in {1..90}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || \
               curl -sf http://localhost:5678 > /dev/null 2>&1; then
              ELAPSED=$(($(date +%s) - START))
              echo "âœ… Accessible after ${ELAPSED}s"
              exit 0
            fi
            [ $((i % 15)) -eq 0 ] && echo "âŒ› Waiting... ($((i * 2))s)"
            sleep 2
          done
          
          echo "âŒ Failed"
          docker compose logs --tail=50 n8n
          exit 1
      
      - name: ğŸ§ª Run test
        id: test
        run: |
          if [ -f "tests/n8n/test_workflows.sh" ]; then
            chmod +x tests/n8n/test_workflows.sh
            bash tests/n8n/test_workflows.sh 2>&1 | tee /tmp/integration-test.log
          else
            echo "No workflow test" | tee /tmp/integration-test.log
          fi
        continue-on-error: true
      
      - name: ğŸ“Š Save metrics
        id: save
        if: always()
        run: |
          mkdir -p /tmp/logs
          
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          
          cp /tmp/integration-test.log /tmp/logs/ 2>/dev/null || echo "No output" > /tmp/logs/integration-test.log
          docker compose logs n8n > /tmp/logs/integration-n8n.log 2>&1 || true
          
          jq -n \
            --arg job "integration" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{job: $job, status: $status, start_time: $start, end_time: $end, duration_seconds: $duration, exit_code: $exit_code}' \
            > /tmp/logs/integration-metrics.json
      
      - name: ğŸ’¾ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: temp-logs-integration
          path: /tmp/logs/
          retention-days: 1
      
      - name: ğŸ§¹ Cleanup
        if: always()
        run: docker compose down -v

  master-e2e:
    name: ğŸ† Master E2E
    runs-on: ubuntu-latest
    timeout-minutes: 18
    needs: [smoke-tests, essential-tests, e2e-tests, n8n-integration]
    outputs:
      duration: ${{ steps.save.outputs.duration }}
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: â±ï¸ Start timer
        id: timer
        run: echo "start_time=$(date +%s)" >> $GITHUB_OUTPUT
      
      - name: ğŸ“¥ Download image
        uses: actions/download-artifact@v4
        with:
          name: n8n-enhanced-image
          path: /tmp
      
      - name: ğŸ“¦ Load image
        run: docker load < /tmp/n8n-enhanced.tar.gz
      
      - name: ğŸ“ Create .env from secrets
        run: |
          cat > .env << EOF
          # Database & Cache
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD_CI }}
          REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD_CI }}
          
          # n8n Authentication
          N8N_USER=${{ secrets.N8N_USER_CI }}
          N8N_PASSWORD=${{ secrets.N8N_PASSWORD_CI }}
          
          # Tor Control
          TOR_CONTROL_PASSWORD=${{ secrets.TOR_CONTROL_PASSWORD_CI }}
          
          # Monitoring
          GRAFANA_USER=${{ secrets.GRAFANA_USER_CI }}
          GRAFANA_PASSWORD=${{ secrets.GRAFANA_PASSWORD_CI }}
          
          # Optional API Keys
          FIRECRAWL_API_KEY=
          JINA_API_KEY=
          EOF
          echo "âœ… .env file created from GitHub Secrets"
      
      - name: ğŸš€ Start full stack (optimized)
        run: |
          # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ
          docker compose up -d postgres redis
          sleep 15
          docker compose up -d n8n
          sleep 10
          docker compose up -d tor prometheus grafana
      
      - name: â±ï¸ Wait for services (max 4 min)
        run: |
          echo "âŒ› Waiting for all services..."
          START=$(date +%s)
          
          # Ğ–Ğ´ĞµĞ¼ n8n
          for i in {1..120}; do
            if curl -sf http://localhost:5678/healthz > /dev/null 2>&1 || \
               curl -sf http://localhost:5678 > /dev/null 2>&1; then
              ELAPSED=$(($(date +%s) - START))
              echo "âœ… n8n ready after ${ELAPSED}s"
              break
            fi
            [ $((i % 20)) -eq 0 ] && echo "âŒ› n8n starting... ($((i * 2))s)"
            sleep 2
          done
          
          # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²ÑĞµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹
          sleep 10
          RUNNING=$(docker compose ps | grep -c "Up" || echo 0)
          echo "ğŸ“Š Running services: $RUNNING"
          
          if [ "$RUNNING" -ge 6 ]; then
            echo "âœ… All services ready"
            docker compose ps
          else
            echo "âš ï¸ Only $RUNNING services up, but continuing..."
            docker compose ps
          fi
      
      - name: ğŸ† Run MASTER TEST
        id: test
        run: |
          chmod +x tests/master/test_full_e2e.sh
          bash tests/master/test_full_e2e.sh 2>&1 | tee /tmp/master-test.log
        continue-on-error: true
      
      - name: ğŸ“Š Save metrics
        id: save
        if: always()
        run: |
          mkdir -p /tmp/logs
          
          END_TIME=$(date +%s)
          START_TIME=${{ steps.timer.outputs.start_time }}
          DURATION=$((END_TIME - START_TIME))
          
          echo "duration=$DURATION" >> $GITHUB_OUTPUT
          
          cp /tmp/master-test.log /tmp/logs/ 2>/dev/null || echo "No output" > /tmp/logs/master-test.log
          docker compose logs --tail=100 n8n > /tmp/logs/master-n8n.log 2>&1
          
          jq -n \
            --arg job "master" \
            --arg status "${{ job.status }}" \
            --argjson start "$START_TIME" \
            --argjson end "$END_TIME" \
            --argjson duration "$DURATION" \
            --arg exit_code "${{ steps.test.outcome }}" \
            '{job: $job, status: $status, start_time: $start, end_time: $end, duration_seconds: $duration, exit_code: $exit_code}' \
            > /tmp/logs/master-metrics.json
      
      - name: ğŸ’¾ Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: temp-logs-master
          path: /tmp/logs/
          retention-days: 1
      
      - name: ğŸ§¹ Cleanup
        if: always()
        run: docker compose down -v

  ctrf-report:
    name: ğŸ“Š Final Report
    runs-on: ubuntu-latest
    needs: [fast-validation, smoke-tests, essential-tests, e2e-tests, n8n-integration, master-e2e]
    if: always()
    steps:
      - name: ğŸ“Š Checkout
        uses: actions/checkout@v4
      
      - name: ğŸ“¥ Download logs
        uses: actions/download-artifact@v4
        with:
          pattern: temp-logs-*
          path: all-temp-logs/
          merge-multiple: true
        continue-on-error: true
      
      - name: ğŸ”€ Merge logs
        run: |
          mkdir -p logs
          if [ -d "all-temp-logs" ]; then
            find all-temp-logs -type f -exec cp {} logs/ \;
          fi
          echo "Collected: $(ls -1 logs/ | wc -l) files"
      
      - name: ğŸ“Š Parse metrics
        run: |
          # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ jq -s Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¸ÑĞ½Ğ¸Ñ JSONĞ¾Ğ²
          if ls logs/*-metrics.json 1> /dev/null 2>&1; then
            jq -s '.' logs/*-metrics.json > /tmp/all-metrics.json 2>/dev/null || echo "[]" > /tmp/all-metrics.json
          else
            echo "[]" > /tmp/all-metrics.json
          fi
          
          echo "Metrics parsed"
          cat /tmp/all-metrics.json
        continue-on-error: true
      
      - name: ğŸ” Extract errors
        run: |
          mkdir -p logs
          
          # Ğ£Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ½Ğ°Ñ ÑĞºÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸Ñ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
          for logfile in logs/*-test.log; do
            if [ -f "$logfile" ]; then
              echo "=== $(basename $logfile) ==="
              grep -i "error\|fail" "$logfile" 2>/dev/null | head -5 || echo "No errors"
              echo ""
            fi
          done > logs/errors-detailed.txt
          
          echo "Errors extracted"
        continue-on-error: true
      
      - name: ğŸ“Š Generate CTRF
        run: |
          PASSED=0
          FAILED=0
          
          [ "${{ needs.fast-validation.result }}" == "success" ] && PASSED=$((PASSED + 1)) || FAILED=$((FAILED + 1))
          [ "${{ needs.smoke-tests.result }}" == "success" ] && PASSED=$((PASSED + 5)) || FAILED=$((FAILED + 5))
          [ "${{ needs.essential-tests.result }}" == "success" ] && PASSED=$((PASSED + 2)) || FAILED=$((FAILED + 2))
          [ "${{ needs.e2e-tests.result }}" == "success" ] && PASSED=$((PASSED + 1)) || FAILED=$((FAILED + 1))
          [ "${{ needs.n8n-integration.result }}" == "success" ] && PASSED=$((PASSED + 1)) || FAILED=$((FAILED + 1))
          [ "${{ needs.master-e2e.result }}" == "success" ] && PASSED=$((PASSED + 1)) || FAILED=$((FAILED + 1))
          
          SUCCESS_RATE=$((PASSED * 100 / 11))
          
          echo "PASSED=$PASSED" >> $GITHUB_ENV
          echo "FAILED=$FAILED" >> $GITHUB_ENV
          echo "SUCCESS_RATE=$SUCCESS_RATE" >> $GITHUB_ENV
          
          DURATION_FAST=${{ needs.fast-validation.outputs.duration }}
          DURATION_E2E=${{ needs.e2e-tests.outputs.duration }}
          DURATION_INTEGRATION=${{ needs.n8n-integration.outputs.duration }}
          DURATION_MASTER=${{ needs.master-e2e.outputs.duration }}
          TOTAL_DURATION=$((DURATION_FAST + DURATION_E2E + DURATION_INTEGRATION + DURATION_MASTER))
          
          # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ CTRF Ğ¾Ñ‚Ñ‡ĞµÑ‚
          jq -n \
            --argjson passed "$PASSED" \
            --argjson failed "$FAILED" \
            --argjson total_duration "$TOTAL_DURATION" \
            --argjson run "${{ github.run_number }}" \
            --arg sha "${{ github.sha }}" \
            '{
              summary: {
                tests: 11,
                passed: $passed,
                failed: $failed,
                duration: ($total_duration * 1000)
              },
              results: {
                tool: {
                  name: "GitHub Actions CI"
                },
                summary: {
                  tests: 11,
                  passed: $passed,
                  failed: $failed,
                  pending: 0,
                  skipped: 0,
                  other: 0,
                  start: 0,
                  stop: 0
                },
                tests: []
              },
              environment: {
                workflow_run: $run,
                workflow_sha: $sha
              }
            }' > logs/ctrf-report.json
          
          echo "CTRF generated"
          cat logs/ctrf-report.json
        continue-on-error: true
      
      - name: ğŸ“ Generate summary
        run: |
          jq -n \
            --argjson run "${{ github.run_number }}" \
            --arg sha "${{ github.sha }}" \
            --argjson passed "${PASSED:-0}" \
            --argjson failed "${FAILED:-0}" \
            --argjson rate "${SUCCESS_RATE:-0}" \
            '{
              run: $run,
              sha: $sha,
              passed: $passed,
              failed: $failed,
              success_rate: $rate
            }' > logs/summary.json
          
          echo "Summary generated"
          cat logs/summary.json
        continue-on-error: true
      
      - name: ğŸ“ Generate diagnostic
        run: |
          cat > logs/diagnostic.md << EOF
          # CI/CD Report
          
          ## Results
          
          - Fast Validation: ${{ needs.fast-validation.result }}
          - Smoke Tests: ${{ needs.smoke-tests.result }}
          - Essential Tests: ${{ needs.essential-tests.result }}
          - E2E Tests: ${{ needs.e2e-tests.result }}
          - Integration: ${{ needs.n8n-integration.result }}
          - Master E2E: ${{ needs.master-e2e.result }}
          
          ## Stats
          
          - Passed: ${PASSED:-0}
          - Failed: ${FAILED:-0}
          - Rate: ${SUCCESS_RATE:-0}%
          EOF
          
          echo "Diagnostic generated"
        continue-on-error: true
      
      - name: ğŸ“ Workflow info
        run: |
          printf "Run: ${{ github.run_number }}\nCommit: ${{ github.sha }}\nBranch: ${{ github.ref_name }}\n" > logs/workflow-info.txt
          ls -1 logs/ > logs/index.txt
          echo "Info generated"
        continue-on-error: true
      
      - name: ğŸ“Š Publish CTRF
        uses: ctrf-io/github-test-reporter@v1
        with:
          report-path: './logs/ctrf-report.json'
          summary-report: true
          test-report: true
          failed-report: true
        continue-on-error: true
      
      - name: ğŸ“¤ Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ci-artifacts-full
          path: |
            logs/
          retention-days: 7
          compression-level: 9
        if: always()
      
      - name: ğŸ§¹ Cleanup
        uses: geekyeggo/delete-artifact@v5
        with:
          name: temp-logs-*
          failOnError: false
        if: always()
